{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Librer√≠as esenciales\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelos y evaluaci√≥n\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo de gr√°ficos\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# import optuna\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados correctamente.\n",
      "Dimensiones - Train: (652515, 14), Test: (569886, 13)\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas de los datasets procesados\n",
    "train_path = \"../data/df_train_processed.feather\"\n",
    "test_path = \"../data/df_test_processed.feather\"\n",
    "\n",
    "# Cargar los datasets\n",
    "df_train = pd.read_feather(train_path)\n",
    "df_test = pd.read_feather(test_path)\n",
    "\n",
    "# Mostrar las dimensiones de los datos cargados\n",
    "print(f\"Datos cargados correctamente.\")\n",
    "print(f\"Dimensiones - Train: {df_train.shape}, Test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 652515 entries, 0 to 699999\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count   Dtype   \n",
      "---  ------               --------------   -----   \n",
      " 0   trip_id              652515 non-null  int64   \n",
      " 1   duration             652515 non-null  int64   \n",
      " 2   start_lat            652515 non-null  float64 \n",
      " 3   start_lon            652515 non-null  float64 \n",
      " 4   end_lat              652515 non-null  float64 \n",
      " 5   end_lon              652515 non-null  float64 \n",
      " 6   trip_route_category  652515 non-null  category\n",
      " 7   passholder_type      652515 non-null  category\n",
      " 8   start_station        652515 non-null  category\n",
      " 9   end_station          652515 non-null  category\n",
      " 10  hour                 652515 non-null  int32   \n",
      " 11  day_of_week          652515 non-null  category\n",
      " 12  year_month           652515 non-null  object  \n",
      " 13  year                 652515 non-null  int32   \n",
      "dtypes: category(5), float64(4), int32(2), int64(2), object(1)\n",
      "memory usage: 49.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569886 entries, 0 to 569885\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype   \n",
      "---  ------               --------------   -----   \n",
      " 0   trip_id              569886 non-null  int64   \n",
      " 1   duration             569886 non-null  int64   \n",
      " 2   start_lat            569886 non-null  float64 \n",
      " 3   start_lon            569886 non-null  float64 \n",
      " 4   end_lat              569886 non-null  float64 \n",
      " 5   end_lon              569886 non-null  float64 \n",
      " 6   trip_route_category  569886 non-null  category\n",
      " 7   start_station        569886 non-null  category\n",
      " 8   end_station          569886 non-null  category\n",
      " 9   hour                 569886 non-null  int32   \n",
      " 10  day_of_week          569886 non-null  category\n",
      " 11  year_month           569886 non-null  object  \n",
      " 12  year                 569886 non-null  int32   \n",
      "dtypes: category(4), float64(4), int32(2), int64(2), object(1)\n",
      "memory usage: 38.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_test.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 652515 entries, 0 to 699999\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count   Dtype   \n",
      "---  ------               --------------   -----   \n",
      " 0   trip_id              652515 non-null  int64   \n",
      " 1   duration             652515 non-null  int64   \n",
      " 2   start_lat            652515 non-null  float64 \n",
      " 3   start_lon            652515 non-null  float64 \n",
      " 4   end_lat              652515 non-null  float64 \n",
      " 5   end_lon              652515 non-null  float64 \n",
      " 6   trip_route_category  652515 non-null  category\n",
      " 7   passholder_type      652515 non-null  category\n",
      " 8   start_station        652515 non-null  category\n",
      " 9   end_station          652515 non-null  category\n",
      " 10  hour                 652515 non-null  int32   \n",
      " 11  day_of_week          652515 non-null  category\n",
      " 12  year_month           652515 non-null  category\n",
      " 13  year                 652515 non-null  int32   \n",
      "dtypes: category(6), float64(4), int32(2), int64(2)\n",
      "memory usage: 44.8 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569886 entries, 0 to 569885\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype   \n",
      "---  ------               --------------   -----   \n",
      " 0   trip_id              569886 non-null  int64   \n",
      " 1   duration             569886 non-null  int64   \n",
      " 2   start_lat            569886 non-null  float64 \n",
      " 3   start_lon            569886 non-null  float64 \n",
      " 4   end_lat              569886 non-null  float64 \n",
      " 5   end_lon              569886 non-null  float64 \n",
      " 6   trip_route_category  569886 non-null  category\n",
      " 7   start_station        569886 non-null  category\n",
      " 8   end_station          569886 non-null  category\n",
      " 9   hour                 569886 non-null  int32   \n",
      " 10  day_of_week          569886 non-null  category\n",
      " 11  year_month           569886 non-null  category\n",
      " 12  year                 569886 non-null  int32   \n",
      "dtypes: category(5), float64(4), int32(2), int64(2)\n",
      "memory usage: 34.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Al guardarlos en formato feather hubo un detalle con datos object, por lo que se deben convertir a categoricos\n",
    "df_train[\"year_month\"] = df_train[\"year_month\"].astype(\"category\")\n",
    "df_test[\"year_month\"] = df_test[\"year_month\"].astype(\"category\")\n",
    "df_train.info()\n",
    "df_test.info()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos\n",
    "\n",
    "Necesitamos dividir los datos en tres conjuntos:\n",
    "1. **Train (70%)** Se usa para entrenar el modelo.  \n",
    "2. **Validation (15%)**  Se usa para ajustar hiperpar√°metros y evaluar el desempe√±o durante el entrenamiento.  \n",
    "3. **Test (15%)** Se usa para evaluar el rendimiento final antes de usar el modelo en producci√≥n.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones despu√©s del split:\n",
      "Train: X_train (456760, 13), y_train (456760,)\n",
      "Validation: X_val (97877, 13), y_val (97877,)\n",
      "Test: X_test (97878, 13), y_test (97878,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir variables predictoras y objetivo\n",
    "X = df_train.drop(columns=[\"passholder_type\"])  # Todas menos la variable objetivo\n",
    "y = df_train[\"passholder_type\"]  # Variable a predecir\n",
    "\n",
    "# Primero separamos 70% train y 30% restante\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "# Ahora dividimos el 30% restante en validaci√≥n (15%) y test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Verificar dimensiones\n",
    "print(f\"Dimensiones despu√©s del split:\")\n",
    "print(f\"Train: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"Validation: X_val {X_val.shape}, y_val {y_val.shape}\")\n",
    "print(f\"Test: X_test {X_test.shape}, y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases codificadas: ['Annual Pass' 'Flex Pass' 'Monthly Pass' 'One Day Pass' 'Testing'\n",
      " 'Walk-up']\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el LabelEncoder y ajustar con los valores de la variable objetivo\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convertir `y_train`, `y_val`, y `y_test` en NumPy arrays para evitar errores\n",
    "y_train = y_train_encoded\n",
    "y_val = y_val_encoded\n",
    "y_test = y_test_encoded\n",
    "\n",
    "# Verificar las clases codificadas\n",
    "print(\"Clases codificadas:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando LightGBM...\n",
      "Accuracy en validaci√≥n: 0.7419\n",
      "\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Annual Pass       0.69      0.37      0.49      4941\n",
      "   Flex Pass       0.64      0.13      0.21      1625\n",
      "Monthly Pass       0.77      0.90      0.83     55853\n",
      "One Day Pass       0.52      0.17      0.26      5904\n",
      "     Testing       0.06      0.14      0.08         7\n",
      "     Walk-up       0.70      0.65      0.68     29547\n",
      "\n",
      "    accuracy                           0.74     97877\n",
      "   macro avg       0.56      0.39      0.42     97877\n",
      "weighted avg       0.73      0.74      0.72     97877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convertir los datasets a formato LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "# Definir hiperpar√°metros del modelo\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": len(label_encoder.classes_),\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"learning_rate\": 0.07,\n",
    "    \"max_depth\": 13,\n",
    "    \"num_leaves\": 43,\n",
    "    \"min_data_in_leaf\": 30,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "# Entrenar modelo sin `early_stopping_rounds`\n",
    "print(\"Entrenando LightGBM...\")\n",
    "lgb_model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    num_boost_round=500\n",
    ")\n",
    "\n",
    "# Predicciones en validaci√≥n\n",
    "y_val_pred_proba = lgb_model.predict(X_val)\n",
    "\n",
    "# Convertir probabilidades a clases\n",
    "y_val_pred = y_val_pred_proba.argmax(axis=1)\n",
    "\n",
    "# Evaluar desempe√±o\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Accuracy en validaci√≥n: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nReporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo LightGBM tiene un **accuracy de 74.14%**, lo cual no est√° mal, pero hay puntos clave que podemos mejorar\n",
    "\n",
    "1. **`Monthly Pass`** es la clase mejor predicha con **f1-score de 0.83**, lo que indica que el modelo captura bien su patr√≥n.\n",
    "2. **`Annual Pass`, `Flex Pass` y `One Day Pass`** tienen baja precisi√≥n y recall, lo que sugiere que el modelo tiene problemas diferenci√°ndolos.\n",
    "3. **`Testing`** es completamente ignorada con un f1-score de **0.00**, lo que indica que el modelo no encuentra ejemplos suficientes para aprender de ella y es logico porque hab√≠a muy pocos datos, quiz√° haciendo un balanceo de clases se podr√≠a mejorar.\n",
    "4. **`Walk-up`** tiene un desempe√±o aceptable pero no √≥ptimo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando XGBoost...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m      4\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m      5\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39mclasses_),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEntrenando XGBoost...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train_encoded\u001b[49m, y_train, eval_set\u001b[38;5;241m=\u001b[39m[(X_val_encoded, y_val)], early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Predicciones\u001b[39;00m\n\u001b[0;32m     18\u001b[0m y_val_pred_xgb \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_val_encoded)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Definir y entrenar el modelo XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(label_encoder.classes_),\n",
    "    learning_rate=0.1,\n",
    "    max_depth=10,\n",
    "    n_estimators=500,\n",
    "    random_state=42,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "print(\"\\nEntrenando XGBoost...\")\n",
    "xgb_model.fit(X_train_encoded, y_train, eval_set=[(X_val_encoded, y_val)], early_stopping_rounds=50, eval_metric=\"mlogloss\", verbose=True)\n",
    "\n",
    "# Predicciones\n",
    "y_val_pred_xgb = xgb_model.predict(X_val_encoded)\n",
    "\n",
    "# Evaluar desempe√±o\n",
    "accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "print(f\"\\nüìä Accuracy en validaci√≥n (XGBoost): {accuracy_xgb:.4f}\")\n",
    "\n",
    "print(\"\\nüìä Reporte de Clasificaci√≥n (XGBoost):\")\n",
    "print(classification_report(y_val, y_val_pred_xgb, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el modelo LightGBM\n",
    "with open(\"lightgbm_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lgb_model, f)\n",
    "\n",
    "\n",
    "\n",
    "print(\"‚úÖ Modelos guardados exitosamente\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entiendo, la estructura de la **submisi√≥n** debe contener dos columnas:\n",
    "\n",
    "1. `trip_id`: Identificador √∫nico del viaje.\n",
    "2. `passholder_type`: Predicci√≥n del tipo de pase (`Monthly Pass`, `Walk-up`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## **üìå Estrategia para construir la submisi√≥n correctamente**\n",
    "### **1Ô∏è‚É£ Transformaciones necesarias antes del modelado**\n",
    "- **Asegurar que `trip_id` est√© presente en el dataset de test**.\n",
    "- **Asegurar que `passholder_type` es la variable objetivo en train**.\n",
    "- **Asegurar consistencia en los tipos de datos entre `df_train` y `df_test`**.\n",
    "- **Generar caracter√≠sticas en `df_test` que existen en `df_train` pero faltan en test**:\n",
    "  - `hour`, `day_of_week`, `year_month`, `year`.\n",
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Modelos candidatos**\n",
    "Dado que el objetivo es **clasificaci√≥n multiclase** (`passholder_type` tiene varias categor√≠as), podemos considerar modelos eficientes y livianos para evitar un peso excesivo:\n",
    "\n",
    "| Modelo | Pros | Contras |\n",
    "|--------|------|---------|\n",
    "| **Random Forest** | Bueno con categ√≥ricas, f√°cil de interpretar | Puede ser pesado si tiene muchas categor√≠as distintas |\n",
    "| **XGBoost** | Eficiente y optimizado para tabulares | Puede ser m√°s lento que otros modelos ligeros |\n",
    "| **LightGBM** | R√°pido y eficiente con datos categ√≥ricos | Puede ser sensible a datos desbalanceados |\n",
    "| **Regresi√≥n Log√≠stica** | Sencillo, interpretativo y liviano | Puede no capturar relaciones no lineales |\n",
    "| **Naive Bayes** | Muy r√°pido en inferencia | Suponiendo independencia de features, lo cual puede no ser realista |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Cargar el modelo LightGBM\n",
    "with open(\"lightgbm_model.pkl\", \"rb\") as f:\n",
    "    lgb_model = pickle.load(f)\n",
    "\n",
    "print(\"‚úÖ Modelos cargados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia para evitar modificar el original\n",
    "df_test_encoded = df_test.copy()\n",
    "\n",
    "# Aplicar los LabelEncoders a las columnas categ√≥ricas\n",
    "for col in label_encoders:\n",
    "    if col in df_test_encoded.columns:\n",
    "        unseen_labels = set(df_test_encoded[col].unique()) - set(label_encoders[col].classes_)\n",
    "\n",
    "        # Solo aplicar reemplazo en 'start_station' y 'end_station'\n",
    "        if unseen_labels and col in [\"start_station\", \"end_station\"]:\n",
    "            print(f\"Valores desconocidos en {col}: {unseen_labels}\")\n",
    "            most_frequent = X_train[col].mode()[0]  # Categor√≠a m√°s frecuente en X_train\n",
    "            df_test_encoded[col] = df_test_encoded[col].apply(lambda x: x if x in label_encoders[col].classes_ else most_frequent)\n",
    "\n",
    "        # Aplicar el label encoding\n",
    "        df_test_encoded[col] = label_encoders[col].transform(df_test_encoded[col])\n",
    "\n",
    "# Asegurar que `df_test_encoded` tenga las mismas columnas que `X_train`\n",
    "df_test_encoded = df_test_encoded[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Verificar que no haya valores nulos\n",
    "print(\"Valores nulos en df_test_encoded despu√©s de preprocesamiento:\", df_test_encoded.isnull().sum().sum())\n",
    "\n",
    "# Obtener las columnas categ√≥ricas de entrenamiento\n",
    "categorical_cols = X_train.select_dtypes(include=[\"category\"]).columns\n",
    "\n",
    "# Convertir a categor√≠a y asignar las mismas categor√≠as que en entrenamiento\n",
    "for col in categorical_cols:\n",
    "    df_test_encoded[col] = df_test_encoded[col].astype(\"category\")\n",
    "    df_test_encoded[col] = df_test_encoded[col].cat.set_categories(X_train[col].cat.categories)\n",
    "\n",
    "# Predecir con LightGBM\n",
    "y_test_pred_proba_lgb = lgb_model.predict(df_test_encoded)\n",
    "\n",
    "# Convertir las probabilidades en etiquetas\n",
    "y_test_pred_lgb = y_test_pred_proba_lgb.argmax(axis=1)\n",
    "\n",
    "# Convertir las etiquetas num√©ricas de vuelta a los nombres originales\n",
    "y_test_pred_lgb_labels = label_encoder.inverse_transform(y_test_pred_lgb)\n",
    "\n",
    "# Crear DataFrame con formato final\n",
    "df_submission_lgb = pd.DataFrame({\n",
    "    \"trip_id\": df_test[\"trip_id\"],  # Mantiene el trip_id original\n",
    "    \"passholder_type\": y_test_pred_lgb_labels\n",
    "})\n",
    "\n",
    "# Guardar en CSV\n",
    "df_submission_lgb.to_csv(\"submission_lightgbm.csv\", index=False)\n",
    "print(\"‚úÖ Predicciones de LightGBM guardadas en 'submission_lightgbm.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkon_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
