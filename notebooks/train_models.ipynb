{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature engineering completado. Archivos guardados en:\n",
      " - C:\\Users\\candy\\Downloads\\arkon_ds\\data\\train.feather\n",
      " - C:\\Users\\candy\\Downloads\\arkon_ds\\data\\test.feather\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# üîπ Funci√≥n para buscar archivos\n",
    "def find_file(filename):\n",
    "    \"\"\"Busca un archivo en la carpeta 'data' dentro del proyecto.\"\"\"\n",
    "    search_dir = Path.cwd()\n",
    "    for parent in [search_dir] + list(search_dir.parents):\n",
    "        possible_path = parent / \"data\" / filename\n",
    "        if possible_path.exists():\n",
    "            return possible_path.resolve()\n",
    "    raise FileNotFoundError(f\"‚ùå No se encontr√≥ el archivo {filename} en la estructura de directorios.\")\n",
    "\n",
    "# üîπ Cargar dataset limpio\n",
    "def load_clean_data(file_name):\n",
    "    \"\"\"Carga el dataset en formato Feather.\"\"\"\n",
    "    file_path = find_file(file_name)\n",
    "    return pd.read_feather(file_path)\n",
    "\n",
    "# üîπ Feature Engineering\n",
    "def feature_engineering(df, is_test=False):\n",
    "    \"\"\"Genera caracter√≠sticas adicionales para el modelo.\"\"\"\n",
    "    \n",
    "    # Extraer d√≠a de la semana y hora del viaje\n",
    "    df[\"day_of_week\"] = df[\"start_time\"].dt.dayofweek\n",
    "    df[\"hour\"] = df[\"start_time\"].dt.hour\n",
    "\n",
    "    # Marcar si es fin de semana\n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Crear categor√≠as de duraci√≥n de viaje\n",
    "    df[\"duration_category\"] = pd.cut(df[\"duration\"],\n",
    "                                     bins=[0, 5, 15, 30, 60, 120, 360],\n",
    "                                     labels=[\"0-5 min\", \"5-15 min\", \"15-30 min\", \"30-60 min\", \"60-120 min\", \"120+ min\"])\n",
    "\n",
    "    # Conversi√≥n de `year_month` a num√©rico\n",
    "    if \"year_month\" in df.columns:\n",
    "        df[\"year_month\"] = df[\"year_month\"].str.replace(\"-\", \"\").astype(int)\n",
    "\n",
    "    # ‚ùå Eliminar columnas irrelevantes (incluyendo `plan_duration`)\n",
    "    cols_to_drop = [\"bike_id\", \"start_time\", \"end_time\", \"plan_duration\"]\n",
    "    df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "    # Convertir variables categ√≥ricas a num√©ricas\n",
    "    categorical_cols = [\"trip_route_category\", \"start_station\", \"end_station\", \"duration_category\"]\n",
    "\n",
    "    if not is_test:\n",
    "        categorical_cols.append(\"passholder_type\")\n",
    "\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        encoder = LabelEncoder()\n",
    "        df[col] = encoder.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = encoder\n",
    "\n",
    "    return df, label_encoders\n",
    "\n",
    "# üîπ Procesar el dataset de entrenamiento (ahora sin `plan_duration`)\n",
    "df_clean = load_clean_data(\"df_clean.feather\")\n",
    "df_features, label_encoders = feature_engineering(df_clean)\n",
    "\n",
    "# Separar variables predictoras (X) y variable objetivo (y)\n",
    "X = df_features.drop(columns=[\"passholder_type\"])\n",
    "y = df_features[\"passholder_type\"]\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Guardar datasets procesados\n",
    "data_dir = find_file(\"df_clean.feather\").parent\n",
    "train_data_path = data_dir / \"train.feather\"\n",
    "test_data_path = data_dir / \"test.feather\"\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "train_data.to_feather(train_data_path)\n",
    "test_data.to_feather(test_data_path)\n",
    "\n",
    "print(f\"‚úÖ Feature engineering completado. Archivos guardados en:\\n - {train_data_path}\\n - {test_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train dataset encontrado en: C:\\Users\\candy\\Downloads\\arkon_ds\\data\\train.feather\n",
      "‚úÖ Test dataset encontrado en: C:\\Users\\candy\\Downloads\\arkon_ds\\data\\test.feather\n",
      "\n",
      "‚úÖ Modelo guardado en: C:\\Users\\candy\\Downloads\\arkon_ds\\data\\random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# üîπ Cargar datasets preprocesados\n",
    "try:\n",
    "    train_path = find_file(\"train.feather\")\n",
    "    test_path = find_file(\"test.feather\")\n",
    "    print(f\"‚úÖ Train dataset encontrado en: {train_path}\")\n",
    "    print(f\"‚úÖ Test dataset encontrado en: {test_path}\")\n",
    "\n",
    "    df_train = pd.read_feather(train_path)\n",
    "    df_test = pd.read_feather(test_path)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    exit(1)\n",
    "\n",
    "# üîπ Separar variables predictoras (X) y variable objetivo (y)\n",
    "X_train = df_train.drop(columns=[\"passholder_type\"])\n",
    "y_train = df_train[\"passholder_type\"]\n",
    "\n",
    "X_test = df_test.drop(columns=[\"passholder_type\"])\n",
    "y_test = df_test[\"passholder_type\"]\n",
    "\n",
    "# üîπ Definir y entrenar el modelo (Random Forest optimizado)\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# üîπ Guardar el modelo entrenado\n",
    "model_path = train_path.parent / \"random_forest_model.pkl\"\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"\\n‚úÖ Modelo guardado en: {model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo encontrado en: C:\\Users\\candy\\Downloads\\arkon_ds\\data\\random_forest_model.pkl\n",
      "‚úÖ Dataset de test encontrado en: C:\\Users\\candy\\Downloads\\arkon_ds\\data\\df_clean_test.feather\n",
      "\n",
      "‚ö†Ô∏è `df_clean_test.feather` no tiene `passholder_type`, por lo que no se pueden calcular m√©tricas de evaluaci√≥n.\n",
      "‚úÖ Predicciones generadas con √©xito.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# üîπ Funci√≥n para buscar archivos en la estructura de directorios\n",
    "def find_file(filename):\n",
    "    \"\"\"Busca un archivo en la carpeta 'data' dentro del proyecto.\"\"\"\n",
    "    search_dir = Path.cwd()\n",
    "    for parent in [search_dir] + list(search_dir.parents):\n",
    "        possible_path = parent / \"data\" / filename\n",
    "        if possible_path.exists():\n",
    "            return possible_path.resolve()\n",
    "    raise FileNotFoundError(f\"‚ùå No se encontr√≥ el archivo {filename} en la estructura de directorios.\")\n",
    "\n",
    "# üîπ Cargar el modelo entrenado\n",
    "try:\n",
    "    model_path = find_file(\"random_forest_model.pkl\")\n",
    "    print(f\"‚úÖ Modelo encontrado en: {model_path}\")\n",
    "    model = joblib.load(model_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    exit(1)\n",
    "\n",
    "# üîπ Cargar el dataset `df_clean_test.feather`\n",
    "try:\n",
    "    test_data_path = find_file(\"df_clean_test.feather\")\n",
    "    print(f\"‚úÖ Dataset de test encontrado en: {test_data_path}\")\n",
    "    df_test = pd.read_feather(test_data_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    exit(1)\n",
    "\n",
    "# üîπ Feature Engineering en `df_clean_test.feather`\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Transforma el dataset para que coincida con el usado en entrenamiento.\"\"\"\n",
    "    \n",
    "    # Extraer d√≠a de la semana y hora del viaje\n",
    "    df[\"day_of_week\"] = df[\"start_time\"].dt.dayofweek\n",
    "    df[\"hour\"] = df[\"start_time\"].dt.hour\n",
    "\n",
    "    # Marcar si es fin de semana\n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Extraer a√±o y mes en formato num√©rico\n",
    "    df[\"year_month\"] = df[\"start_time\"].dt.strftime(\"%Y%m\").astype(int)\n",
    "    df[\"year\"] = df[\"start_time\"].dt.year.astype(int)\n",
    "\n",
    "    # Categorizar duraci√≥n del viaje\n",
    "    df[\"duration_category\"] = pd.cut(df[\"duration\"],\n",
    "                                     bins=[0, 5, 15, 30, 60, 120, 360],\n",
    "                                     labels=[0, 1, 2, 3, 4, 5]).astype(\"int32\")\n",
    "\n",
    "    # üîπ Asegurar que todas las columnas categ√≥ricas sean convertidas a num√©ricas\n",
    "    categorical_cols = [\"trip_route_category\", \"start_station\", \"end_station\"]\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(\"category\").cat.codes  # Convertir a num√©rico\n",
    "\n",
    "    # Eliminar columnas irrelevantes\n",
    "    df.drop(columns=[\"bike_id\", \"start_time\", \"end_time\", \"plan_duration\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# üîπ Aplicar Feature Engineering al dataset de test\n",
    "df_test = feature_engineering(df_test)\n",
    "\n",
    "# üîπ Verificar si `passholder_type` existe en `df_clean_test.feather`\n",
    "if \"passholder_type\" in df_test.columns:\n",
    "    y_test = df_test[\"passholder_type\"]\n",
    "    df_test.drop(columns=[\"passholder_type\"], inplace=True)  # Lo eliminamos para que coincida con entrenamiento\n",
    "    print(\"‚ö†Ô∏è `passholder_type` fue eliminado de `df_test` para evitar problemas en la predicci√≥n.\")\n",
    "else:\n",
    "    y_test = None  # No hay etiquetas reales, solo podemos hacer predicciones sin evaluaci√≥n\n",
    "\n",
    "# üîπ Asegurar que las columnas coincidan con las del modelo entrenado\n",
    "expected_features = list(model.feature_names_in_)  # Mantener el orden de las columnas\n",
    "df_test = df_test[expected_features]  # Reordenar `df_test` seg√∫n entrenamiento\n",
    "\n",
    "# üîπ Realizar predicciones con el modelo entrenado\n",
    "y_pred = model.predict(df_test)\n",
    "\n",
    "# üîπ Evaluar el desempe√±o del modelo en `df_clean_test.feather`\n",
    "if y_test is not None:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    print(f\"\\n‚úÖ **Evaluaci√≥n del Modelo en Datos No Vistos**\")\n",
    "    print(f\"‚úÖ Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"‚úÖ Precision: {precision:.4f}\")\n",
    "    print(f\"‚úÖ Recall: {recall:.4f}\")\n",
    "    print(f\"‚úÖ F1 Score: {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nüîπ Reporte de Clasificaci√≥n:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # üîπ Matriz de Confusi√≥n\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nüîπ Matriz de Confusi√≥n:\")\n",
    "    print(conf_matrix)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è `df_clean_test.feather` no tiene `passholder_type`, por lo que no se pueden calcular m√©tricas de evaluaci√≥n.\")\n",
    "    print(\"‚úÖ Predicciones generadas con √©xito.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predicciones guardadas en: C:\\Users\\candy\\Downloads\\arkon_ds\\data\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# üîπ Guardar las predicciones en un archivo CSV\n",
    "df_test[\"predicted_passholder_type\"] = y_pred\n",
    "output_path = test_data_path.parent / \"predictions.csv\"\n",
    "df_test.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Predicciones guardadas en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkon_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
