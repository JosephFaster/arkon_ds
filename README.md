# arkon_ds
 Prueba tÃ©cnica para Arkon data
# ğŸš´â€â™‚ï¸ PredicciÃ³n de Tipos de Pase en un Sistema de Bicicletas Compartidas

## ğŸ“Œ DescripciÃ³n
Este repositorio contiene el cÃ³digo y los datos utilizados en el anÃ¡lisis y modelado para la predicciÃ³n del tipo de pase (`passholder_type`) en un sistema de bicicletas compartidas. A lo largo del desarrollo, se realizaron mÃºltiples modificaciones y experimentos con diferentes enfoques de preprocesamiento, feature engineering y modelos de machine learning.

Si se exploran los **commits**, se puede ver que el repositorio fue modificado muchas veces, esto sin contar los archivos que nunca fueron indexados a Git. Hubo varias iteraciones de preprocesamiento, optimizaciÃ³n de modelos y cambios en la organizaciÃ³n del cÃ³digo.

## ğŸ“‚ Estructura del Repositorio

```
â”œâ”€â”€ data/                  # Contiene todos los datos utilizados en el anÃ¡lisis y modelado
â”œâ”€â”€ notebooks/             # Incluye los notebooks con el flujo de trabajo y experimentos
â”œâ”€â”€ docker/                # Carpeta vacÃ­a, se planeaba contenerizaciÃ³n pero no se alcanzÃ³
â”œâ”€â”€ notebooks/             # Notebooks con el anÃ¡lisis y pruebas de modelos
â”œâ”€â”€ main.py                # Script principal (en caso de implementaciÃ³n)
â”œâ”€â”€ label_encoder.pkl      # Modelo de codificaciÃ³n de etiquetas guardado
â”œâ”€â”€ lightgbm_model.pkl     # Modelo LightGBM entrenado
â”œâ”€â”€ requirements.txt       # Dependencias necesarias para reproducir el entorno
â”œâ”€â”€ Dockerfile             # Archivo para contenerizaciÃ³n (no implementado por falta de tiempo)
â””â”€â”€ README.md              # DocumentaciÃ³n del proyecto
```

## âš™ï¸ Modelos y Resultados
Se probaron varios modelos de Machine Learning, incluyendo **Random Forest, XGBoost y LightGBM**. Los modelos mÃ¡s complejos alcanzaron una precisiÃ³n del **92% en promedio**, pero tenÃ­an un peso de alrededor de **1 GB cada uno**, lo que impidiÃ³ subirlos a GitHub, incluso usando Git LFS.

DespuÃ©s de varias pruebas de **feature engineering** y optimizaciÃ³n, se optÃ³ por un modelo mÃ¡s ligero para garantizar que los recursos fueran manejables sin sacrificar demasiada precisiÃ³n.

## ğŸš€ DesafÃ­os y Limitaciones
1. **Tiempo y recursos:** Se intentÃ³ implementar un sistema mÃ¡s robusto con **Docker**, pero por falta de tiempo no se logrÃ³ poner en producciÃ³n.
2. **Procesamiento de datos:** Se realizaron mÃºltiples estrategias de limpieza y preprocesamiento, pero el formato de `submission` en Kaggle limitÃ³ algunas decisiones.
3. **Espacio en GitHub:** Debido al tamaÃ±o de los modelos, se tuvieron que descartar algunos y trabajar con versiones mÃ¡s livianas.
4. **Pipeline automatizado:** Se generÃ³ un flujo de trabajo para facilitar la replicabilidad del modelo, pero algunas partes quedaron en experimentaciÃ³n.

## ğŸ“Œ Notas Finales
El proyecto pasÃ³ por muchas iteraciones y pruebas de modelado antes de llegar a la versiÃ³n final. La carpeta `docker/` quedÃ³ vacÃ­a porque no se alcanzÃ³ a implementar la puesta en producciÃ³n, y la estructura de carpetas fue reorganizada varias veces para optimizar el flujo de trabajo.

Este README resume los aspectos mÃ¡s relevantes del repositorio y del proceso de desarrollo. Â¡Gracias por revisar el proyecto! ğŸš´â€â™‚ï¸ğŸ“Š



